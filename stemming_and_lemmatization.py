# -*- coding: utf-8 -*-
"""stemming and lemmatization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E5aCIU-jFaTRxP7LLLc1S7i855pa_HAx
"""

import nltk
nltk.download("all")

from nltk.corpus import stopwords

stopw=[i for i in stopwords.words('english')]
stopw[:10]

from nltk.tokenize import sent_tokenize,word_tokenize
from nltk.stem import WordNetLemmatizer # for lemmatization
from nltk.stem import PorterStemmer # for stemming

data="i am doing great sometimes then i use feet to do not know"

wtoken=word_tokenize(data)  # word tokenize --- on behalf of space sep words

# removing stopwords
remove_stop_words=[word for word in wtoken if word not in stopw]
remove_stop_words

# stemming
ps=PorterStemmer()
for i in remove_stop_words:
  print("stemming of word is ",ps.stem(i))

# now it's time for lemmatization
lem=WordNetLemmatizer()
for i in remove_stop_words:
  print("lemma of the word is ",lem.lemmatize(i))

